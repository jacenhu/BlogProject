# 什么是数据湖？及其架构（上）

**声明：本文原文为：[What is Data Lake? It's Architecture](https://www.guru99.com/data-lake-architecture.html)，图片源自原文，译者@Jacen，转载请注明。**

## 什么是数据湖？

数据湖（Data Lake）是可以存储大量结构化、半结构化和非结构化数据的存储仓库。它是一个以其原生格式存储每种类型数据的场所，对帐户大小或文件没有固定限制。它提供大量数据，以提高分析性能和原生集成。

数据湖就像一个大容器，与真实的湖泊和河流非常相似。就像在湖中有多个支流进入一样，数据湖具有结构化数据，非结构化数据，机器对机器，实时流经的日志。


![dataLake-pic](./../../.vuepress/public/img/dataLake/dataLake.png)

数据湖使数据更易处理，是一种经济高效的方式来存储组织的所有数据以供以后处理。数据分析师可以专注于发现数据中的有意义的模式，而不是数据本身。

与将数据存储在文件和文件夹中的分层数据仓库不同，Data lake具有扁平的体系结构。数据湖中的每个数据元素都有一个唯一的标识符，并用一组元数据信息进行标记。

## 为什么需要使用数据湖？

建立数据湖的主要目的是向数据科学家提供未完善的数据视图。

使用数据湖的理由如下：

* 随着诸如Hadoop之类的存储引擎的兴起，存储不同的信息变得十分容易。无需使用数据湖将数据建模到企业范围的架构中。
* 随着数据量、数据质量以及元数据的增加，分析的质量也随之提高。
* 数据湖提供业务敏捷性
* 机器学习和人工智能可用于做出有收益的预测。
* 它为组织提供了竞争优势。
* 没有数据筒仓结构。数据湖提供了全面的客户视图，并使分析更加强大。

## 数据湖的架构

![dataLake-architecture-pic](./../../.vuepress/public/img/dataLake/dataLakeArchitecture.png)

本图展示了一个业务数据湖的架构。较低的级别表示大多数情况下处于空闲状态的数据，而较高的级别表示实时事务数据。数据流经系统时，无延时或者几乎无延时。以下是数据湖架构中重要的层：

1、提取层：左侧的层描述了数据源。数据可以批量或者实时加载到数据湖中。

2、洞察层：右侧的层代表使用系统洞察力的分析方。SQL、NoSQL查询，甚至excel都可以用于数据分析。

3、HDFS：是针对结构化和非结构化数据的低成本解决方案。它是系统中所有静止数据的着陆区。

4、蒸馏层：从存储层中获取数据，并将其转为为结构化数据，以便分析。

5、处理层：以不同的实时、交互式、批处理方式运行分析算法和用户查询，以生成便于分析的结构化数据。

6、统一层：控制系统管理和监控。它包括审计和熟练度管理、数据管理、工作流管理。

## 关键的数据湖概念

以下是人们需要了解的关键的数据湖概念，以完全理解数据湖架构。

![dataLake-concept-pic](./../../.vuepress/public/img/dataLake/dataLakeConcept.png)

**数据提取**

数据提取允许连接器从其他数据源获取数据并将其加载到数据湖中。

数据提取支持：

* 所有类型的结构化、半结构化和非结构化数据。
* 多种提取方式，如：批处理、实时、一次性加载。
* 多源数据，如：数据库、Web服务、电子邮件、物联网和FTP。

**数据存储**

数据存储应可扩展，提供了经济高效的存储，并允许快速的进行数据浏览。它需要支持多种类型的数据格式。

**数据治理**

数据治理是管理组织中使用的数据的可用性、安全性和完整性的过程。

**安全**

安全性需要在数据湖的每一层实现。它从存储、发掘和消费开始。基本需要是停止未经授权的用户访问。它应支持使用易于浏览的GUI和仪表盘访问数据的各种工具。身份验证、计费、授权和数据保护是数据湖安全的一些重要特性。

**数据质量**

数据质量是数据湖架构的重要组成部分。数据被用于提取商业价值。从质量差的数据中洞察会导致低质量的洞察结果。

**数据发现**

在开始准备数据或分析之前，数据发现是另一个重要阶段。在此阶段，通过组织和解释被提取到数据湖中的数据，使用标记技术来表达对数据的理解。

**数据审计**

两个主要的数据审计任务是跟踪对关键数据集的更改。

1、跟踪重要数据集元素的更改

2、捕获如何/何时/以及谁对这些元素进行更改。

数据审计有助于评估风险和合规性。

**数据沿袭**

这部分处理数据的来源。它主要处理随着时间变迁它移动到了那里以及发生了什么。它简化了数据分析过程中从起点到终点的错误纠正。

**数据探索**

它是数据分析的开始阶段。在启动数据探索之前，它有助于识别正确的数据集。

所有给定的组件需要协同工作，以便在数据湖构建中发挥重要作用，轻松的演进和探索环境。